{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exam\n",
    "## Tran Trong Hieu_24MSE23185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from scipy.signal import wiener\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "\n",
    "def show_image(title, image, cmap = None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    if cmap:\n",
    "        plt.imshow(image, cmap = cmap)\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Object Counting \n",
    "\n",
    "Given a color JPG image named ‘Ex1.jpg’.\n",
    "\n",
    "(a) Read and display the original image.\n",
    "\n",
    "(b) Binarize the original image using Otsu method and display the binary image.\n",
    "\n",
    "(c) Fill small holes in the binary image and display the filled image.\n",
    "\n",
    "(d) Perform the erosion on the binary image using a suitable structuring element and size.\n",
    "\n",
    "(e) Apply region labeling on the eroded image to count number of stones in the original image. Print \n",
    "the result on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) - Read and display the original image\n",
    "image_path = 'Ex1.jpg'\n",
    "original_image = cv2.imread(image_path)\n",
    "original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for display\n",
    "show_image('Original Image', original_image_rgb)\n",
    "\n",
    "# (b) - Binarize the image using Otsu's method\n",
    "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "_, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "show_image('Binary Image', binary_image, cmap = 'gray')\n",
    "\n",
    "# (c) - Fill small holes in the binary image\n",
    "filled_image = binary_fill_holes(binary_image // 255).astype(np.uint8) * 255\n",
    "show_image('Filled Image', filled_image, cmap = 'gray')\n",
    "\n",
    "# (d) - Perform erosion on the binary image\n",
    "se = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (4, 5))\n",
    "eroded_image = cv2.erode(filled_image, se)\n",
    "show_image('Eroded Image', eroded_image, cmap = 'gray')\n",
    "\n",
    "# (e) - Apply region labeling to count objects\n",
    "labeled_image, num_objects = label(eroded_image, connectivity = 2, return_num = True)\n",
    "\n",
    "# Create a color label image\n",
    "colored_labels = np.zeros((*labeled_image.shape, 3), dtype = np.uint8)\n",
    "for region in regionprops(labeled_image):\n",
    "    for coord in region.coords:\n",
    "        colored_labels[coord[0], coord[1]] = np.random.randint(0, 255, size = 3)\n",
    "\n",
    "show_image('Labeled Image', colored_labels)\n",
    "\n",
    "# Print the number of objects\n",
    "print(f'Number of objects: {num_objects}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Denoise and Deblur a Noisy Blurry Grayscale Image \n",
    "\n",
    "Given a noisy and blurry grayscale PNG image named ‘Ex2.jpg’.\n",
    "\n",
    "(a) Read and display the original image.\n",
    "\n",
    "(b) Method 1: Apply a denoise filter (5x5 averaging kernel filter) then a sharpening filter (h = [0, -1, 0; -1, 6, -1; 0, -1, 0] / 2) to the original image. Display the restored image.\n",
    "\n",
    "(c) Method 2: Apply the Wiener filter to denoise and deblur the original image. Assume the Gaussian noise variance of the original image is σ=0.04. The estimated noise is calculated by the noise variance divided by the variance of the original image. The sharpening filter using the same with question b. Display the restored image.\n",
    "\n",
    "(d) Perform the root mean square (rms) calculation in two methods between the restored image and the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Mean Square Error function\n",
    "def rms_error(original, restored):\n",
    "    return np.sqrt(np.mean((original - restored) ** 2))\n",
    "\n",
    "# (a) Read and display the original image\n",
    "image_path = 'Ex2.jpg'\n",
    "original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "show_image(\"Original Image\", original_image, cmap = 'gray')\n",
    "\n",
    "# (b) Method 1: Apply denoise filter and sharpening filter\n",
    "# Denoise using a 5x5 averaging kernel\n",
    "kernel = np.ones((5, 5), np.float32) / 25\n",
    "denoised_image = cv2.filter2D(original_image, -1, kernel)\n",
    "\n",
    "# Sharpen using the given sharpening filter\n",
    "sharpening_filter = np.array([[0, -1, 0],\n",
    "                              [-1, 6, -1],\n",
    "                              [0, -1, 0]]) / 2.0\n",
    "sharpened_image = cv2.filter2D(denoised_image, -1, sharpening_filter, borderType = cv2.BORDER_REFLECT)\n",
    "show_image(\"Restored Image (Method 1)\", sharpened_image, cmap = 'gray')\n",
    "\n",
    "# (c) Method 2: Wiener filter and sharpening\n",
    "# Calculate estimated noise variance\n",
    "noise_variance = 0.04\n",
    "image_variance = np.var(original_image)\n",
    "estimated_noise = noise_variance / image_variance\n",
    "\n",
    "# Apply Wiener filter\n",
    "wiener_image = wiener(original_image, mysize = (5, 5), noise = estimated_noise)\n",
    "\n",
    "# Sharpen the Wiener-filtered image\n",
    "sharpened_wiener_image = cv2.filter2D(wiener_image, -1, sharpening_filter, borderType = cv2.BORDER_REFLECT)\n",
    "show_image(\"Restored Image (Method 2)\", sharpened_wiener_image, cmap = 'gray')\n",
    "\n",
    "# (d) Perform RMS calculation\n",
    "rms_method1 = rms_error(original_image, sharpened_image)\n",
    "rms_method2 = rms_error(original_image, sharpened_wiener_image)\n",
    "\n",
    "print(f\"RMS Error (Method 1): {rms_method1}\")\n",
    "print(f\"RMS Error (Method 2): {rms_method2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Edge Detection and Hough Transform \n",
    "\n",
    "Given a color JPG image named ‘Ex3.jpg’.\n",
    "\n",
    "(a) Read and display the original image in color and grayscale format.\n",
    "\n",
    "(b) Apply Roberts filter in two directions (horizontal [1 0; 0 -1] and vertical [0 1; -1 0]). Display the logarithm of sum of edge magnitude response with a threhold value = 5000. Then, display the binary image based on this threshold.\n",
    "\n",
    "(c) Apply Canny Edge Detector using a suitable standard deviation σ and a suitable threshold value.\n",
    "\n",
    "(d) Apply Hough Transform using a ratio = 0.2 of max peak and NhoodSize = [49 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Read and display the original image in color and grayscale format\n",
    "image_path = 'Ex3.jpg'\n",
    "original_image = cv2.imread(image_path)  # Read as a color image\n",
    "original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for display\n",
    "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "\n",
    "show_image(\"Original Image (Color)\", original_image_rgb)\n",
    "show_image(\"Original Image (Grayscale)\", gray_image, cmap = 'gray')\n",
    "\n",
    "# (b) Apply Roberts filter in two directions\n",
    "# Define Roberts filters\n",
    "roberts_horizontal = np.array([[1, 0], [0, -1]])\n",
    "roberts_vertical = np.array([[0, 1], [-1, 0]])\n",
    "\n",
    "# Apply filters\n",
    "horizontal_edges = cv2.filter2D(gray_image.astype(float), -1, roberts_horizontal)\n",
    "vertical_edges = cv2.filter2D(gray_image.astype(float), -1, roberts_vertical)\n",
    "\n",
    "# Compute edge magnitude\n",
    "edge_magnitude = horizontal_edges ** 2 + vertical_edges ** 2\n",
    "\n",
    "# Apply logarithmic transformation\n",
    "log_edge_magnitude = np.log(1 + edge_magnitude)\n",
    "log_edge_magnitude = log_edge_magnitude / np.max(log_edge_magnitude)\n",
    "\n",
    "# Thresholding (threshold = 5000)\n",
    "threshold_value = 4000\n",
    "binary_image = (edge_magnitude > threshold_value).astype(np.uint8)\n",
    "\n",
    "show_image(\"Log Edge Magnitude (Roberts)\", log_edge_magnitude, cmap = 'gray')\n",
    "show_image(\"Binary Image (Threshold > 5000)\", binary_image, cmap = 'gray')\n",
    "\n",
    "# (c) Apply Canny Edge Detector\n",
    "# Set suitable parameters (adjust if needed)\n",
    "sigma = 1.0  # Standard deviation for Gaussian blur\n",
    "low_threshold = 50  # Lower threshold for edge detection\n",
    "high_threshold = 150  # Upper threshold for edge detection\n",
    "\n",
    "# Apply Canny Edge Detector\n",
    "canny_edges = cv2.Canny(gray_image, low_threshold, high_threshold)\n",
    "show_image(\"Canny Edge Detector\", canny_edges, cmap = 'gray')\n",
    "\n",
    "# (d) Apply Hough Transform\n",
    "# Hough Transform\n",
    "h, theta, d = hough_line(canny_edges)\n",
    "\n",
    "# Find peaks in Hough transform\n",
    "_, angles, dists = hough_line_peaks(h, theta, d, threshold = 0.8 * np.max(h))\n",
    "\n",
    "# Apply Hough Line Transform\n",
    "# You can adjust the parameters to filter out the unwanted lines\n",
    "lines = cv2.HoughLinesP(canny_edges, 1, np.pi / 90, threshold = 100, minLineLength = 50, maxLineGap = 2)\n",
    "\n",
    "# Create a copy of the original image to draw the lines on\n",
    "# Create a copy of the original image to draw the lines on\n",
    "img_color = original_image_rgb.copy()\n",
    "\n",
    "# Draw the detected lines on the image\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        # Draw the line on the image with green color and line width of 2\n",
    "        cv2.line(img_color, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "show_image(\"Hough Transform Lines\", img_color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Key point Detection \n",
    "\n",
    "Given a color JPG image named ‘Ex4.jpg’.\n",
    "\n",
    "(a) Read and display the original image in color and grayscale format.\n",
    " \n",
    "(b) Use LoG to highlight the 100 strongest key points in the original image. Choose sigma value = 2*sqrt(2). \n",
    "\n",
    "(c) Use DoH to highlight the 100 strongest key points in the original image. Choose sigma value = 3. \n",
    "\n",
    "(d) Use FAST to highlight the 100 strongest key points in the original image. Choose the threshold value = 0.2. \n",
    "\n",
    "All cases used Prewitt operator if needed. Other parameters are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Read and display the original image in color and grayscale format\n",
    "image_path = \"Ex4.jpg\"\n",
    "original_image = cv2.imread(image_path)\n",
    "original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "\n",
    "show_image(\"Original Image (Color)\", original_image_rgb)\n",
    "show_image(\"Original Image (Grayscale)\", gray_image, cmap = \"gray\")\n",
    "\n",
    "# (b) Laplacian of Gaussian (LoG) keypoint detection\n",
    "sigma_log = 2 * np.sqrt(2)\n",
    "log_response = cv2.GaussianBlur(gray_image, (0, 0), sigmaX = sigma_log, sigmaY = sigma_log, borderType = cv2.BORDER_DEFAULT)\n",
    "log_response = cv2.Laplacian(log_response, cv2.CV_64F)\n",
    "thresholded_log = log_response.copy()\n",
    "thresholded_log[thresholded_log < 0.05 * np.max(log_response)] = 0\n",
    "\n",
    "local_maxima = peak_local_max(log_response, min_distance = 5, num_peaks = 100)\n",
    "img_keypoints_log = original_image.copy()\n",
    "for point in local_maxima:\n",
    "    cv2.drawMarker(img_keypoints_log, tuple(point[::-1]), (0, 0, 255), markerType = cv2.MARKER_CROSS, markerSize = 10)\n",
    "\n",
    "show_image(\"LoG Response\", log_response, cmap = \"gray\")\n",
    "show_image(\"Thresholded LoG Response\", thresholded_log, cmap = \"gray\")\n",
    "show_image(\"Local Extrema (Dilated)\", thresholded_log > 0, cmap = \"gray\")\n",
    "show_image(\"Keypoints (LoG)\", cv2.cvtColor(img_keypoints_log, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# (c) Determinant of Hessian (DoH) keypoint detection\n",
    "sigma_doh = 3\n",
    "gaussian = cv2.GaussianBlur(gray_image, (0, 0), sigmaX = sigma_doh, sigmaY = sigma_doh, borderType = cv2.BORDER_DEFAULT)\n",
    "dxx = cv2.Sobel(gaussian, cv2.CV_64F, 2, 0, ksize = 5)\n",
    "dyy = cv2.Sobel(gaussian, cv2.CV_64F, 0, 2, ksize = 5)\n",
    "dxy = cv2.Sobel(gaussian, cv2.CV_64F, 1, 1, ksize = 5)\n",
    "doh_response = dxx * dyy - dxy**2\n",
    "\n",
    "thresholded_doh = doh_response.copy()\n",
    "thresholded_doh[thresholded_doh < 0.05 * np.max(doh_response)] = 0\n",
    "\n",
    "local_maxima_doh = peak_local_max(doh_response, min_distance = 5, num_peaks = 100)\n",
    "img_keypoints_doh = original_image_rgb.copy()\n",
    "for point in local_maxima_doh:\n",
    "    cv2.drawMarker(img_keypoints_doh, tuple(point[::-1]), (255, 0, 0), markerType = cv2.MARKER_CROSS, markerSize = 10)\n",
    "\n",
    "show_image(\"DoH Response\", doh_response, cmap = \"gray\")\n",
    "show_image(\"Thresholded DoH Response\", thresholded_doh, cmap = \"gray\")\n",
    "show_image(\"Local Maxima (Dilated)\", thresholded_doh > 0, cmap = \"gray\")\n",
    "show_image(\"Keypoints (DoH)\", cv2.cvtColor(img_keypoints_doh, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# (d) FAST Keypoint Detection\n",
    "fast = cv2.FastFeatureDetector_create(threshold = 20, nonmaxSuppression = False)\n",
    "keypoints = fast.detect(gray_image, None)\n",
    "\n",
    "img_keypoints_fast = cv2.drawKeypoints(original_image_rgb, keypoints, None, color = (0, 255, 0))\n",
    "\n",
    "fast.setNonmaxSuppression(True)\n",
    "keypoints_nonmax = fast.detect(gray_image, None)\n",
    "\n",
    "img_keypoints_fast_nonmax = cv2.drawKeypoints(original_image_rgb, keypoints_nonmax, None, color = (0, 0, 255))\n",
    "\n",
    "show_image(\"Fast Corners\", cv2.cvtColor(img_keypoints_fast, cv2.COLOR_BGR2RGB))\n",
    "show_image(\"Fast Corners, Non-max Suppressed\", cv2.cvtColor(img_keypoints_fast_nonmax, cv2.COLOR_BGR2RGB))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
