{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import histeq_modified as hm\n",
    "\n",
    "FS = 15 # Fontsize of caption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Global Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image (grayscale)\n",
    "image = cv2.imread('moon.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Display the original image and its histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(\"Original Image\", fontsize = FS)\n",
    "plt.axis('off')\n",
    "\n",
    "# Histogram of the original image\n",
    "plt.subplot(2, 2, 2)\n",
    "hist, bins = np.histogram(image.flatten(), 256, [0, 256])\n",
    "plt.bar(bins[:-1], hist, width=1, color='gray', edgecolor='black')\n",
    "plt.title(\"Histogram Before Equalization\", fontsize = FS)\n",
    "plt.xlabel(\"Gray Level\")\n",
    "plt.ylabel(\"% of Pixels\")\n",
    "plt.grid()\n",
    "\n",
    "# Apply histogram equalization\n",
    "equalized_image = cv2.equalizeHist(image)\n",
    "\n",
    "# Equalized image\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(equalized_image, cmap='gray')\n",
    "plt.title(\"Equalized Image\", fontsize = FS)\n",
    "plt.axis('off')\n",
    "\n",
    "# Histogram of the equalized image\n",
    "plt.subplot(2, 2, 4)\n",
    "hist_eq, bins_eq = np.histogram(equalized_image.flatten(), 256, [0, 256])\n",
    "plt.bar(bins_eq[:-1], hist_eq, width=1, color='gray', edgecolor='black')\n",
    "plt.title(\"Histogram After Equalization\", fontsize = FS)\n",
    "plt.xlabel(\"Gray Level\")\n",
    "plt.ylabel(\"% of Pixels\")\n",
    "plt.grid()\n",
    "\n",
    "# Show the results\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Contrast Limited Adaptive Histogram Equalization (CLAHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image = cv2.imread('moon.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Parameters\n",
    "clip_ratios = [1.0, 0.7, 0.4, 0.1]  # Clipping ratios\n",
    "\n",
    "# Compute original histogram\n",
    "hist, bins = np.histogram(image.flatten(), 256, [0, 256])\n",
    "max_count = hist.max()\n",
    "\n",
    "# Prepare results storage\n",
    "limited_eq_images = []\n",
    "LUT = np.zeros((len(clip_ratios), 256), dtype=np.uint8)\n",
    "\n",
    "# Loop over different clipping ratios\n",
    "for i, clip_ratio in enumerate(clip_ratios):\n",
    "    clip_value = clip_ratio * max_count\n",
    "    # Clip histogram\n",
    "    clipped_hist = np.clip(hist, 0, clip_value)\n",
    "\n",
    "    # Generate virtual pixel values for histogram equalization\n",
    "    clipped_values = []\n",
    "    for level in range(256):\n",
    "        clipped_values.extend([level] * int(clipped_hist[level]))\n",
    "    \n",
    "    # Create mapping function via histogram equalization\n",
    "    clipped_values = np.array(clipped_values, dtype=np.uint8)\n",
    "    temp, mapping = cv2.calcHist([clipped_values], [0], None, [256], [0, 256]), None\n",
    "    T = np.cumsum(clipped_hist) / np.cumsum(clipped_hist)[-1]\n",
    "    T = np.clip(T, 0, 1)\n",
    "    \n",
    "    LUT[i, :] = (T * 255).astype(np.uint8)\n",
    "\n",
    "    # Apply mapping to the original image\n",
    "    limited_eq_images.append(cv2.LUT(image, LUT[i, :]))\n",
    "\n",
    "# Display results\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, eq_img in enumerate(limited_eq_images):\n",
    "    plt.subplot(1, len(clip_ratios), i + 1)\n",
    "    plt.imshow(eq_img, cmap='gray')\n",
    "    plt.title(f'Clip Ratio: {clip_ratios[i]}', fontsize=FS)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Original histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(bins[:-1], hist, width=1, color='gray', edgecolor='black')\n",
    "plt.title('Original Histogram', fontsize=FS)\n",
    "plt.xlabel('Gray Level', fontsize=FS)\n",
    "plt.ylabel('Pixel Count', fontsize=FS)\n",
    "plt.grid()\n",
    "\n",
    "# LUTs\n",
    "plt.subplot(1, 2, 2)\n",
    "for i, lut in enumerate(LUT):\n",
    "    plt.plot(lut, label=f'Clip Ratio: {clip_ratios[i]}', linewidth=2)\n",
    "plt.title('Mapping Functions (LUT)', fontsize=FS)\n",
    "plt.xlabel('Input Intensity', fontsize=FS)\n",
    "plt.ylabel('Output Intensity', fontsize=FS)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Adaptive Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "I = cv2.imread('parrot.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Perform global histogram equalization\n",
    "eq_I = cv2.equalizeHist(I)\n",
    "\n",
    "# Perform local histogram equalization (using blocks)\n",
    "def local_hist_eq(img, block_size = (200, 200)):\n",
    "    rows, cols = img.shape\n",
    "    out_img = np.zeros_like(img)\n",
    "    \n",
    "    # Define the block size\n",
    "    block_h, block_w = block_size\n",
    "    \n",
    "    # Iterate over the image in blocks\n",
    "    for i in range(0, rows, block_h):\n",
    "        for j in range(0, cols, block_w):\n",
    "            block = img[i:i+block_h, j:j+block_w]\n",
    "            out_img[i:i+block_h, j:j+block_w] = cv2.equalizeHist(block)\n",
    "    \n",
    "    return out_img\n",
    "\n",
    "lc_I = local_hist_eq(I)\n",
    "\n",
    "# Display the images\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(I, cmap = 'gray')\n",
    "plt.title('Original image', fontsize = FS)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(eq_I, cmap = 'gray')\n",
    "plt.title('Global Equalization', fontsize = FS)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(lc_I, cmap = 'gray')\n",
    "plt.title('Local Equalization', fontsize = FS)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot histograms\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Histogram before equalization\n",
    "count, bins = np.histogram(I.flatten(), bins = 256, range = [0, 255])\n",
    "ax[0].bar(bins[:-1], count, width = 1)\n",
    "ax[0].set_title('Histogram before equalization', fontsize = FS)\n",
    "ax[0].set_xlim([0, 255])\n",
    "ax[0].set_xlabel('Gray level')\n",
    "ax[0].set_ylabel('% of pixels')\n",
    "\n",
    "# Histogram after global equalization\n",
    "count, bins = np.histogram(eq_I.flatten(), bins = 256, range = [0, 255])\n",
    "ax[1].bar(bins[:-1], count, width=1)\n",
    "ax[1].set_title('Histogram after global equalization', fontsize = FS)\n",
    "ax[1].set_xlim([0, 255])\n",
    "ax[1].set_xlabel('Gray level')\n",
    "ax[1].set_ylabel('% of pixels')\n",
    "\n",
    "# Histogram after local equalization\n",
    "count, bins = np.histogram(lc_I.flatten(), bins = 256, range = [0, 255])\n",
    "ax[2].bar(bins[:-1], count, width=1)\n",
    "ax[2].set_title('Histogram after local equalization', fontsize = FS)\n",
    "ax[2].set_xlim([0, 255])\n",
    "ax[2].set_xlabel('Gray level')\n",
    "ax[2].set_ylabel('% of pixels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Convolution between an image and a simple filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "I = cv2.imread('airplane.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Constract three different filters\n",
    "h1 = np.ones((1, 10)) / 10 # horizontal filter\n",
    "h2 = np.ones((10, 1)) / 10 # vertical filter\n",
    "h3 = np.ones((10, 10)) / 100 # box/windown filter\n",
    "\n",
    "# Perform filtering on the noisy image\n",
    "filtered_I1 = cv2.filter2D(I, -1, h1)\n",
    "filtered_I2 = cv2.filter2D(I, -1, h2)\n",
    "filtered_I3 = cv2.filter2D(I, -1, h3)\n",
    "\n",
    "# Show the images\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Horizontal filtering\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(I, cmap = 'gray')\n",
    "plt.title('Original image', fontsize = FS)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(filtered_I1, cmap = 'gray')\n",
    "plt.title('Horizontal filtering', fontsize = FS)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Show Vertical filtering\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(I, cmap = 'gray')\n",
    "plt.title('Original image', fontsize = FS)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(filtered_I2, cmap = 'gray')\n",
    "plt.title('Vertical filtering', fontsize = FS)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Show Box filtering\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(I, cmap = 'gray')\n",
    "plt.title('Original image', fontsize = FS)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(filtered_I3, cmap = 'gray')\n",
    "plt.title('Box filtering', fontsize = FS)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "I = cv2.imread('bike.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Normalize the image to 0-1 (similar to im2double in MATLAB)\n",
    "I = I.astype(np.float32) / 255.0\n",
    "\n",
    "# Get the dimensions of the image\n",
    "row, column = I.shape\n",
    "\n",
    "# Perform subsampling by matrix multiplication\n",
    "# Create the matrices h1 and h2\n",
    "a = np.eye(row // 2)  # Identity matrix\n",
    "b = np.array([1, 0])  # Vector for horizontal subsampling\n",
    "c = np.array([0.5, 0.5])  # Vector for combined subsampling\n",
    "\n",
    "h1 = np.kron(a, b)  # Kronecker product\n",
    "h2 = np.kron(a, c)  # Kronecker product\n",
    "\n",
    "# Perform subsampling\n",
    "# sub_I1 = h1.T @ I @ h1  # h1.T: transpose of h1\n",
    "# sub_I2 = h2.T @ I @ h2\n",
    "\n",
    "# Perform subsampling by taking every second row and column\n",
    "sub_I1 = I[::2, ::2]  # Method 1: Take every second row and column\n",
    "\n",
    "# Method 2: A more advanced subsampling (weighted)\n",
    "sub_I2 = (I[::2, ::2] + I[1::2, ::2] + I[::2, 1::2] + I[1::2, 1::2]) / 4  # Averaging 4 neighboring pixels\n",
    "\n",
    "# Show images\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Original image, Method 1, and Method 2\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(I, cmap = 'gray')\n",
    "plt.title('Original image', fontsize = FS)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(sub_I1, cmap = 'gray')\n",
    "plt.title('Method 1', fontsize = FS)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(sub_I2, cmap = 'gray')\n",
    "plt.title('Method 2', fontsize = FS)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
